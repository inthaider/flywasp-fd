window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "src", "modulename": "src", "kind": "module", "doc": "<p>This is the root level documentation for my project.</p>\n\n<p>Here, you can provide an overview of what your project does, its main features, etc.</p>\n"}, {"fullname": "src.RNN_Implementation", "modulename": "src.RNN_Implementation", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess", "modulename": "src.data_preprocess", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.feature_engineering", "modulename": "src.data_preprocess.feature_engineering", "kind": "module", "doc": "<p>This module contains the <code>FeatureEngineer</code> class for performing feature engineering on a Pandas DataFrame.</p>\n\n<p>The <code>FeatureEngineer</code> class includes methods for standardizing features and performing other feature engineering steps. It uses the <code>StandardScaler</code> class from the <code>sklearn.preprocessing</code> module to standardize features.</p>\n\n<p>Classes:\n    FeatureEngineer:\n        A class for performing feature engineering on a Pandas DataFrame. It includes methods for standardizing features and performing other feature engineering steps.</p>\n\n<p>Example:\n    To use the FeatureEngineer class to standardize features of a DataFrame:</p>\n\n<pre><code>&gt;&gt;&gt; df = pd.DataFrame(data)\n&gt;&gt;&gt; feature_engineer = FeatureEngineer(df)\n&gt;&gt;&gt; df_standardized = feature_engineer.engineer_features()\n</code></pre>\n"}, {"fullname": "src.data_preprocess.feature_engineering.logger", "modulename": "src.data_preprocess.feature_engineering", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_preprocess.feature_engineering (WARNING)&gt;"}, {"fullname": "src.data_preprocess.feature_engineering.FeatureEngineer", "modulename": "src.data_preprocess.feature_engineering", "qualname": "FeatureEngineer", "kind": "class", "doc": "<p>A class for performing feature engineering on a Pandas DataFrame.</p>\n\n<p>Attributes:\n    df (pandas.DataFrame): The DataFrame to perform feature engineering on.\n    scaler (sklearn.preprocessing.StandardScaler): The scaler object used to standardize the features.</p>\n\n<p>Methods:\n    standardize_features(columns_to_scale): Standardizes the specified columns in the DataFrame.\n    engineer_features(): Performs feature engineering steps on the DataFrame.</p>\n"}, {"fullname": "src.data_preprocess.feature_engineering.FeatureEngineer.__init__", "modulename": "src.data_preprocess.feature_engineering", "qualname": "FeatureEngineer.__init__", "kind": "function", "doc": "<p>Initializes FeatureEngineer with the given DataFrame.</p>\n\n<p>Args:\n    df (pandas.DataFrame): The DataFrame to perform feature engineering on.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.data_preprocess.feature_engineering.FeatureEngineer.df", "modulename": "src.data_preprocess.feature_engineering", "qualname": "FeatureEngineer.df", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.feature_engineering.FeatureEngineer.scaler", "modulename": "src.data_preprocess.feature_engineering", "qualname": "FeatureEngineer.scaler", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.feature_engineering.FeatureEngineer.standardize_features", "modulename": "src.data_preprocess.feature_engineering", "qualname": "FeatureEngineer.standardize_features", "kind": "function", "doc": "<p>Standardizes the specified columns in the DataFrame.</p>\n\n<p>Args:\n    columns_to_scale (list): The columns to standardize.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">columns_to_scale</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.feature_engineering.FeatureEngineer.engineer_features", "modulename": "src.data_preprocess.feature_engineering", "qualname": "FeatureEngineer.engineer_features", "kind": "function", "doc": "<p>Performs feature engineering steps on the DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing", "modulename": "src.data_preprocess.preprocessing", "kind": "module", "doc": "<p>This module contains the <code>DataPreprocessor</code> class for preprocessing a Pandas DataFrame.</p>\n\n<p>The <code>DataPreprocessor</code> class includes methods for loading data, saving processed data, dropping columns, rearranging columns, calculating means, adding labels, handling infinite and NaN values, and performing other preprocessing steps. It uses the <code>pandas</code> and <code>numpy</code> libraries for data manipulation and the <code>logging</code> library for logging.</p>\n\n<p>Classes:\n    DataPreprocessor:\n        A class for preprocessing a Pandas DataFrame. It includes methods for loading data, saving processed data, dropping columns, rearranging columns, calculating means, adding labels, handling infinite and NaN values, and performing other preprocessing steps.</p>\n\n<p>Example:\n    To preprocess a dataset using the DataPreprocessor class:</p>\n\n<pre><code>&gt;&gt;&gt; preprocessor = DataPreprocessor(pickle_path='path/to/data.pkl')\n&gt;&gt;&gt; df_processed = preprocessor.preprocess_data(save_data=True)\n</code></pre>\n\n<p>Note:\n    This module expects the raw data to be in a Pandas DataFrame format and to be available at the specified pickle path.</p>\n"}, {"fullname": "src.data_preprocess.preprocessing.logger", "modulename": "src.data_preprocess.preprocessing", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_preprocess.preprocessing (WARNING)&gt;"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor", "kind": "class", "doc": "<p>A class for preprocessing a Pandas DataFrame.</p>\n\n<p>Attributes:\n    df_raw (pd.DataFrame): The raw DataFrame.\n    df (pd.DataFrame): The processed DataFrame.\n    pickle_path (str): The path to the pickled file.\n    raw_data_id (str): The ID of the raw data.\n    save_data (bool): Whether to save the processed data to a pickled file.\n    raw_data_path (str): The path to the raw data.\n    interim_data_path (str): The path to the interim data.\n    processed_data_path (str): The path to the processed data.\n    timestamp (str): The timestamp of the processed data.</p>\n\n<p>Methods:\n    load_data(): Loads the DataFrame from a pickled file.\n    save_processed_data(): Saves the processed data to a pickled file.\n    drop_columns(columns_to_drop): Drops the specified columns from the DataFrame.\n    specific_rearrange(col_to_move, ref_col): Moves a column to be immediately after a reference column.\n    rearrange_columns(cols_order): Rearranges the columns of the DataFrame according to the specified order.\n    calculate_means(column_pairs, new_columns): Calculates the means of pairs of columns and adds the results as new columns.\n    add_labels(condition_columns, new_column): Adds a new column based on conditions of existing columns.\n    handle_infinity_and_na(): Replaces infinite and NaN values in the DataFrame with forward/backward filled values.\n    preprocess_data(save_data): Performs preprocessing steps on the DataFrame.</p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.__init__", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.__init__", "kind": "function", "doc": "<p>Initializes a new instance of the DataPreprocessor class.</p>\n\n<p>Args:\n    pickle_path (str, optional): The path to the pickled file. Defaults to None.\n    raw_data_id (str, optional): The ID of the raw data. Defaults to \"ff-mw\".\n    save_data (bool, optional): Whether to save the processed data to a pickled file. Defaults to False.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">pickle_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">raw_data_id</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;ff-mw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">save_data</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.df_raw", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.df_raw", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.df", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.df", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.pickle_path", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.pickle_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.raw_data_id", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.raw_data_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.save_data", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.save_data", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.raw_data_path", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.raw_data_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.interim_data_path", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.interim_data_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.processed_data_path", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.processed_data_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.timestamp", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.timestamp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.load_data", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.load_data", "kind": "function", "doc": "<p>Loads the DataFrame from a pickled file.</p>\n\n<p>Returns:\n    pd.DataFrame: The loaded DataFrame.</p>\n\n<p>Raises:\n    ValueError: If an invalid pickle path is provided.\n    Exception: If an error occurs while loading data.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.save_processed_data", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.save_processed_data", "kind": "function", "doc": "<p>Saves the processed data to a pickled file.</p>\n\n<p>Returns:\n    str: The path to the saved file.</p>\n\n<p>Raises:\n    Exception: If an error occurs while saving processed data.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.drop_columns", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.drop_columns", "kind": "function", "doc": "<p>Drops the specified columns from the DataFrame.</p>\n\n<p>Args:\n    columns_to_drop (list of str): The names of the columns to drop.</p>\n\n<p>Raises:\n    Exception: If an error occurs while dropping columns.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">columns_to_drop</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.specific_rearrange", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.specific_rearrange", "kind": "function", "doc": "<p>Moves a column to be immediately after a reference column.</p>\n\n<p>Args:\n    col_to_move (str): The name of the column to move.\n    ref_col (str): The name of the reference column.</p>\n\n<p>Raises:\n    Exception: If an error occurs while moving a column.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">col_to_move</span>, </span><span class=\"param\"><span class=\"n\">ref_col</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.rearrange_columns", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.rearrange_columns", "kind": "function", "doc": "<p>Rearranges the columns of the DataFrame according to the specified order.</p>\n\n<p>Args:\n    cols_order (list of str): The order of the columns.</p>\n\n<p>Raises:\n    Exception: If an error occurs while rearranging columns.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">cols_order</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.calculate_means", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.calculate_means", "kind": "function", "doc": "<p>Calculates the means of pairs of columns and adds the results as new columns.</p>\n\n<p>Args:\n    column_pairs (list of list of str): The pairs of columns to calculate the means of.\n    new_columns (list of str): The names of the new columns.</p>\n\n<p>Raises:\n    Exception: If an error occurs while calculating means.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">column_pairs</span>, </span><span class=\"param\"><span class=\"n\">new_columns</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.add_labels", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.add_labels", "kind": "function", "doc": "<p>Adds a new column based on conditions of existing columns.</p>\n\n<p>Args:\n    condition_columns (list of str): The names of the columns to use for the conditions.\n    new_column (str): The name of the new column.</p>\n\n<p>Raises:\n    Exception: If an error occurs while adding labels.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">condition_columns</span>, </span><span class=\"param\"><span class=\"n\">new_column</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.handle_infinity_and_na", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.handle_infinity_and_na", "kind": "function", "doc": "<p>Replaces infinite and NaN values in the DataFrame with forward/backward filled values.</p>\n\n<p>Raises:\n    Exception: If an error occurs while handling infinite and NaN values.</p>\n\n<p>TODO: Do we need the df.reset_index(drop=True) line?\nTODO: Implement forward and backward filling.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.preprocessing.DataPreprocessor.preprocess_data", "modulename": "src.data_preprocess.preprocessing", "qualname": "DataPreprocessor.preprocess_data", "kind": "function", "doc": "<p>Performs preprocessing steps on the DataFrame.</p>\n\n<p>Args:\n    save_data (bool, optional): Whether to save the processed data to a pickled file. Defaults to None.</p>\n\n<p>Returns:\n    pd.DataFrame: The processed DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">save_data</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.rnn_data_prep", "modulename": "src.data_preprocess.rnn_data_prep", "kind": "module", "doc": "<p>This module contains the <code>DataPreprocessor</code> class for preprocessing a Pandas DataFrame.</p>\n\n<p>The <code>DataPreprocessor</code> class includes methods for loading data, saving processed data, dropping columns, rearranging columns, calculating means, adding labels, and performing other preprocessing steps. It uses the <code>pandas</code> and <code>numpy</code> libraries for data manipulation and the <code>logging</code> library for logging.</p>\n\n<p>Classes:\n    DataPreprocessor:\n        A class for preprocessing a Pandas DataFrame. It includes methods for loading data, saving processed data, dropping columns, rearranging columns, calculating means, adding labels, and performing other preprocessing steps.</p>\n\n<p>Example:\n    To prepare data for RNN training, instantiate the RNNDataPrep class and call the get_rnn_data method:</p>\n\n<pre><code>&gt;&gt;&gt; rnn_data_prep = RNNDataPrep()\n&gt;&gt;&gt; X_train, Y_train, X_test, Y_test = rnn_data_prep.get_rnn_data(sequence_length=5, split_ratio=0.7)\n</code></pre>\n\n<p>Note:\n    The module assumes the presence of a 'data/interim/' directory containing the raw data in pickle format and a 'data/processed/rnn_input/' directory for saving processed data. The class is designed to work with time-series or sequence data, which is typical for RNN models.</p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.logger", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_preprocess.rnn_data_prep (WARNING)&gt;"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep", "kind": "class", "doc": "<p>A class for preparing data for an RNN model.</p>\n\n<p>Attributes:\n    pickle_path (str): The path to the raw data in pickle format.\n    train_test_data_par_dir (str): The parent directory for saving the train and test datasets.\n    save_train_test (bool): If True, the train and test datasets are saved.\n    save_data (bool): If True, the processed data is saved.\n    df_raw (pd.DataFrame): The raw data as a Pandas DataFrame.\n    df (pd.DataFrame): The processed data as a Pandas DataFrame.\n    timestamp (str): The timestamp for the current run.\n    raw_data_path (Path): The path to the raw data.\n    interim_data_path (Path): The path to the interim data.\n    processed_data_path (Path): The path to the processed data.\n    train_test_data_dir (Path): The path to the train and test datasets.\n    raw_data_id (str): The hash value of the raw data.\n    preprocessor (DataPreprocessor): The DataPreprocessor object for preprocessing the raw data.\n    feature_engineer (FeatureEngineer): The FeatureEngineer object for performing feature engineering on the preprocessed data.\n    test_indices (np.ndarray): The indices of the target values for the test sequences.</p>\n\n<p>Methods:\n    get_rnn_data(load_processed, load_train_test, sequence_length, split_ratio, save_data, save_train_test): Provides an interface for either loading preprocessed data or preprocessing raw data, performing feature engineering, preparing sequences and train-test splits, and saving the processed data and train-test splits.\n    load_and_preprocess_data(save_data): Loads the raw data and performs preprocessing and feature engineering steps.\n    prepare_rnn_data(df, sequence_length, split_ratio, rand_oversample, save_train_test): Prepares the train and test datasets for the RNN model.\n    _prep_train_test_seqs(df, sequence_length, split_ratio): Prepares training and testing sequences for the RNN model.\n    _create_seqs(data, sequence_length, index_start): Creates sequences of length <code>sequence_length</code> from the input <code>data</code>.\n    _perform_random_oversampling(X_train, Y_train): Performs random oversampling to balance the class distribution.\n    _load_train_test_data(): Loads the train and test datasets for the RNN model from 4 .pkl files.\n    _save_train_test_data(X_train, Y_train, X_test, Y_test): Saves the train and test datasets for the RNN model as .pkl files.</p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.__init__", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.__init__", "kind": "function", "doc": "<p>Initializes the RNNDataPrep object.</p>\n\n<p>Args:\n    pickle_path (str, optional): The path to the raw data in pickle format. Defaults to \"data/interim/ff-mw.pkl\".\n    train_test_data_par_dir (str, optional): The parent directory for saving the train and test datasets. Defaults to \"data/processed/rnn_input/\".\n    save_train_test (bool, optional): If True, the train and test datasets are saved. Defaults to False.\n    save_data (bool, optional): If True, the processed data is saved. Defaults to False.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">pickle_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;data/interim/ff-mw.pkl&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">train_test_data_par_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;data/processed/rnn_input/&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">save_train_test</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">save_data</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.pickle_path", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.pickle_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.train_test_data_par_dir", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.train_test_data_par_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.save_train_test", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.save_train_test", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.save_data", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.save_data", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.df_raw", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.df_raw", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.df", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.df", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.timestamp", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.timestamp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.raw_data_path", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.raw_data_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.interim_data_path", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.interim_data_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.processed_data_path", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.processed_data_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.train_test_data_dir", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.train_test_data_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.raw_data_id", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.raw_data_id", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.preprocessor", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.preprocessor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.feature_engineer", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.feature_engineer", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.test_indices", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.test_indices", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.get_rnn_data", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.get_rnn_data", "kind": "function", "doc": "<p>Provides an interface for either loading preprocessed data or preprocessing raw data, performing feature engineering, preparing sequences and train-test splits, and saving the processed data and train-test splits.</p>\n\n<p>Args:\n    load_processed (bool, optional): If True, preprocessed data is loaded. Defaults to False.\n    load_train_test (bool, optional): If True, train and test datasets are loaded. Defaults to False.\n    sequence_length (int, optional): The length of the sequences. Defaults to 3.\n    split_ratio (float, optional): The ratio of train to test sequences. Defaults to 2/3.\n    save_data (bool, optional): If True, the processed data is saved. Defaults to None.\n    save_train_test (bool, optional): If True, the train and test datasets are saved. Defaults to None.</p>\n\n<p>Returns:\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: The train and test datasets as NumPy arrays.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">load_processed</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">load_train_test</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">split_ratio</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.6666666666666666</span>,</span><span class=\"param\">\t<span class=\"n\">save_data</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">save_train_test</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.load_and_preprocess_data", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.load_and_preprocess_data", "kind": "function", "doc": "<p>Loads the raw data and performs preprocessing and feature engineering steps.</p>\n\n<p>Args:\n    save_data (bool, optional): If True, the processed data is saved. Defaults to None.</p>\n\n<p>Returns:\n    pd.DataFrame: The processed data as a Pandas DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">save_data</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_preprocess.rnn_data_prep.RNNDataPrep.prepare_rnn_data", "modulename": "src.data_preprocess.rnn_data_prep", "qualname": "RNNDataPrep.prepare_rnn_data", "kind": "function", "doc": "<p>Prepares the train and test datasets for the RNN model.</p>\n\n<p>Args:\n    df (pd.DataFrame): The DataFrame to prepare the train and test datasets from.\n    sequence_length (int, optional): The length of the sequences. Defaults to 3.\n    split_ratio (float, optional): The ratio of train to test sequences. Defaults to 2/3.\n    rand_oversample (bool, optional): If True, random oversampling is performed to balance the class distribution. Defaults to False.\n    save_train_test (bool, optional): If True, the train and test datasets are saved. Defaults to None.</p>\n\n<p>Returns:\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: The train and test datasets as NumPy arrays.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">split_ratio</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.6666666666666666</span>,</span><span class=\"param\">\t<span class=\"n\">rand_oversample</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">save_train_test</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.main", "modulename": "src.main", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.main.logger", "modulename": "src.main", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.main (WARNING)&gt;"}, {"fullname": "src.main.main", "modulename": "src.main", "qualname": "main", "kind": "function", "doc": "<p>Main function that performs data preprocessing, feature engineering, model training, and model saving.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>None</strong></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models", "modulename": "src.models", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.models.baseline_models", "modulename": "src.models.baseline_models", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.models.helpers_rnn", "modulename": "src.models.helpers_rnn", "kind": "module", "doc": "<p>This module contains helper functions for training a Recurrent Neural Network (RNN) on a dataset.</p>\n\n<p>It includes functions for plotting predicted probabilities, creating and processing dataframes for plotting, flagging frames, calculating and plotting means, saving the trained model and configuration settings, checking for NaN and inf values in the input tensor, computing the sum of squared gradients and parameters for a given model, checking for NaN and inf values in the gradients of a given model, and checking for NaN and inf values in the loss value.</p>\n\n<p>Functions:\n    plot_predicted_probabilities(df, test_indices, test_labels_and_probs) -> pd.DataFrame, pd.DataFrame: \n        Plots the predicted probabilities using the _make_df_for_plotting(), _process_df_for_plotting(), and _calculate_and_plot_means() functions.\n    _make_df_for_plotting(df, test_indices, test_true_labels, test_pred_probs) -> pd.DataFrame: \n        Creates a DataFrame for plotting.\n    _process_df_for_plotting(plot_df) -> pd.DataFrame: \n        Processes the DataFrame for plotting.\n    _flag_frames(df, frame_distance=200) -> pd.DataFrame: \n        Flags frames that are within frame_distance of the start frame.\n    _calculate_and_plot_means(plot_df) -> pd.DataFrame: \n        Calculates and plots the means.\n    save_model_and_config(model, model_name, timestamp, pickle_path, processed_data_path, config, model_dir, config_dir) -> None: \n        Saves the trained model and configuration settings.\n    debug_input_nan_inf(inputs) -> None: \n        Checks for NaN and inf values in the input tensor.\n    debug_sumsq_grad_param(model, sum_sq_gradients, sum_sq_parameters) -> float, float: \n        Computes the sum of squared gradients and parameters for a given model.\n    debug_grad_nan_inf(model, epoch, i) -> None: \n        Checks for NaN and inf values in the gradients of a given model.\n    debug_loss_nan_inf(epoch, i, loss) -> None: \n        Checks for NaN and inf values in the loss value.</p>\n"}, {"fullname": "src.models.helpers_rnn.logger", "modulename": "src.models.helpers_rnn", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.models.helpers_rnn (WARNING)&gt;"}, {"fullname": "src.models.helpers_rnn.plot_predicted_probabilities", "modulename": "src.models.helpers_rnn", "qualname": "plot_predicted_probabilities", "kind": "function", "doc": "<p>Plot the predicted probabilities using the _make_df_for_plotting(), _process_df_for_plotting(), and _calculate_and_plot_means() functions.</p>\n\n<p>Args:\n    df (pandas.DataFrame): The DataFrame containing the data.\n    test_indices (numpy.ndarray): The indices of the test data.\n    test_labels_and_probs (numpy.ndarray): A numpy array containing the true labels, predicted labels, and predicted probabilities.</p>\n\n<p>Returns:\n    plot_df (pandas.DataFrame): The processed DataFrame for plotting.\n    mean_df (pandas.DataFrame): The DataFrame containing the calculated means.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span>, </span><span class=\"param\"><span class=\"n\">test_indices</span>, </span><span class=\"param\"><span class=\"n\">test_labels_and_probs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.helpers_rnn.save_model_and_config", "modulename": "src.models.helpers_rnn", "qualname": "save_model_and_config", "kind": "function", "doc": "<p>Saves the trained model and configuration settings.</p>\n\n<p>Args:\n    model (torch.nn.Module): The trained RNN model.\n    model_name (str): The name of the model.\n    timestamp (str): The timestamp to use in the output file names.\n    pickle_path (str): The path to the input data pickle file.\n    processed_data_path (str): The path to the processed data pickle file.\n    config (dict): The configuration settings for the model.\n    model_dir (pathlib.Path): The directory to save the trained model.\n    config_dir (pathlib.Path): The directory to save the configuration settings.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span>,</span><span class=\"param\">\t<span class=\"n\">model_name</span>,</span><span class=\"param\">\t<span class=\"n\">timestamp</span>,</span><span class=\"param\">\t<span class=\"n\">pickle_path</span>,</span><span class=\"param\">\t<span class=\"n\">processed_data_path</span>,</span><span class=\"param\">\t<span class=\"n\">config</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span>,</span><span class=\"param\">\t<span class=\"n\">config_dir</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.helpers_rnn.debug_input_nan_inf", "modulename": "src.models.helpers_rnn", "qualname": "debug_input_nan_inf", "kind": "function", "doc": "<p>Checks for NaN and inf values in the input tensor.</p>\n\n<p>Args:\n    inputs (torch.Tensor): The input tensor.</p>\n\n<p>Raises:\n    AssertionError: If any NaN or inf values are found in the input tensor.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">inputs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.helpers_rnn.debug_sumsq_grad_param", "modulename": "src.models.helpers_rnn", "qualname": "debug_sumsq_grad_param", "kind": "function", "doc": "<p>Computes the sum of squared gradients and parameters for a given model.</p>\n\n<p>Args:\n    model (torch.nn.Module): The model to compute the sum of squared gradients and parameters for.\n    sum_sq_gradients (float): The current sum of squared gradients.\n    sum_sq_parameters (float): The current sum of squared parameters.</p>\n\n<p>Returns:\n    sum_sq_gradients (float): The updated sum of squared gradients.\n    sum_sq_parameters (float): The updated sum of squared parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">sum_sq_gradients</span>, </span><span class=\"param\"><span class=\"n\">sum_sq_parameters</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.helpers_rnn.debug_grad_nan_inf", "modulename": "src.models.helpers_rnn", "qualname": "debug_grad_nan_inf", "kind": "function", "doc": "<p>Checks for NaN and inf values in the gradients of a given model.</p>\n\n<p>Args:\n    model (torch.nn.Module): The model to check the gradients of.\n    epoch (int): The current epoch number.\n    i (int): The current iteration number.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">epoch</span>, </span><span class=\"param\"><span class=\"n\">i</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.helpers_rnn.debug_loss_nan_inf", "modulename": "src.models.helpers_rnn", "qualname": "debug_loss_nan_inf", "kind": "function", "doc": "<p>Checks for NaN and inf values in the loss value.</p>\n\n<p>Args:\n    epoch (int): The current epoch number.\n    i (int): The current iteration number.\n    loss (torch.Tensor): The loss value.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">epoch</span>, </span><span class=\"param\"><span class=\"n\">i</span>, </span><span class=\"param\"><span class=\"n\">loss</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.rnn_model", "modulename": "src.models.rnn_model", "kind": "module", "doc": "<p>This module contains the implementation of a Recurrent Neural Network (RNN) model for time series prediction.</p>\n\n<p>It includes the <code>RNN</code> class for the model, the <code>WalkDataset</code> class for the dataset, and several helper functions for initializing the weights of the model parameters, loading the training and testing data into PyTorch DataLoader objects, initializing the weights for the CrossEntropyLoss function, and configuring the model for training.</p>\n\n<p>Classes:\n    RNN:\n        A class representing the RNN model.\n    WalkDataset:\n        A class representing the dataset.</p>\n\n<p>Functions:\n    init_param_weights(m):\n        Initializes the weights of the model parameters.\n    data_loaders(X_train, Y_train, X_test, Y_test, batch_size):\n        Loads the training and testing data into PyTorch DataLoader objects.\n    _init_cross_entropy_weights(Y_train):\n        Initializes the weights for the CrossEntropyLoss function.\n    loss_function(Y_train):\n        Returns the CrossEntropyLoss function with weights.\n    configure_model(Y_train, input_size, hidden_size, output_size, learning_rate, device, batch_first=True):\n        Configures an RNN model for training.</p>\n"}, {"fullname": "src.models.rnn_model.logger", "modulename": "src.models.rnn_model", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.models.rnn_model (WARNING)&gt;"}, {"fullname": "src.models.rnn_model.RNN", "modulename": "src.models.rnn_model", "qualname": "RNN", "kind": "class", "doc": "<p>A class representing the RNN model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_size</strong> (int):\nThe number of expected features in the input.</li>\n<li><strong>hidden_size</strong> (int):\nThe number of features in the hidden state.</li>\n<li><strong>output_size</strong> (int):\nThe number of output features.</li>\n<li><strong>batch_first</strong> (bool, optional):\nIf True, then the input and output tensors are provided as (batch, seq, feature).\nDefault is True.</li>\n</ul>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "src.models.rnn_model.RNN.__init__", "modulename": "src.models.rnn_model", "qualname": "RNN.__init__", "kind": "function", "doc": "<p>Initialize the RNN model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_size</strong> (int):\nThe number of expected features in the input.</li>\n<li><strong>hidden_size</strong> (int):\nThe number of features in the hidden state.</li>\n<li><strong>output_size</strong> (int):\nThe number of output features.</li>\n<li><strong>batch_first</strong> (bool, optional):\nIf True, then the input and output tensors are provided as (batch, seq, feature).\nDefault is True.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_size</span>, </span><span class=\"param\"><span class=\"n\">hidden_size</span>, </span><span class=\"param\"><span class=\"n\">output_size</span>, </span><span class=\"param\"><span class=\"n\">batch_first</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "src.models.rnn_model.RNN.timestamp", "modulename": "src.models.rnn_model", "qualname": "RNN.timestamp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.RNN.hidden_size", "modulename": "src.models.rnn_model", "qualname": "RNN.hidden_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.RNN.rnn", "modulename": "src.models.rnn_model", "qualname": "RNN.rnn", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.RNN.fc", "modulename": "src.models.rnn_model", "qualname": "RNN.fc", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.RNN.sigmoid", "modulename": "src.models.rnn_model", "qualname": "RNN.sigmoid", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.RNN.forward", "modulename": "src.models.rnn_model", "qualname": "RNN.forward", "kind": "function", "doc": "<p>Forward pass of the RNN model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (torch.Tensor):\nThe input data.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: The output data.</li>\n</ul>\n\n<h6 id=\"notes\">Notes</h6>\n\n<p>Using <code>.to(x.device)</code> in the <code>forward()</code> method ensures that the model\n    is moved to the same device as the input data.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.rnn_model.WalkDataset", "modulename": "src.models.rnn_model", "qualname": "WalkDataset", "kind": "class", "doc": "<p>A class representing the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (numpy.ndarray):\nThe input data.</li>\n<li><strong>Y</strong> (numpy.ndarray):\nThe target data.</li>\n</ul>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "src.models.rnn_model.WalkDataset.__init__", "modulename": "src.models.rnn_model", "qualname": "WalkDataset.__init__", "kind": "function", "doc": "<p>Initialize the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (numpy.ndarray):\nThe input data.</li>\n<li><strong>Y</strong> (numpy.ndarray):\nThe target data.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">X</span>, </span><span class=\"param\"><span class=\"n\">Y</span></span>)</span>"}, {"fullname": "src.models.rnn_model.WalkDataset.X", "modulename": "src.models.rnn_model", "qualname": "WalkDataset.X", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.WalkDataset.Y", "modulename": "src.models.rnn_model", "qualname": "WalkDataset.Y", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.models.rnn_model.init_param_weights", "modulename": "src.models.rnn_model", "qualname": "init_param_weights", "kind": "function", "doc": "<p>Optional function for weight initialization.</p>\n\n<p>Uses Xavier uniform initialization for weights and constant initialization\nfor biases.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>m</strong> (torch.nn.Module):\nThe module to initialize. Only applies to Linear layers.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">m</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.rnn_model.data_loaders", "modulename": "src.models.rnn_model", "qualname": "data_loaders", "kind": "function", "doc": "<p>Loads the training and testing data into PyTorch DataLoader objects.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X_train</strong> (numpy.ndarray):\nThe training input data.</li>\n<li><strong>Y_train</strong> (numpy.ndarray):\nThe training target data.</li>\n<li><strong>X_test</strong> (numpy.ndarray):\nThe testing input data.</li>\n<li><strong>Y_test</strong> (numpy.ndarray):\nThe testing target data.</li>\n<li><strong>batch_size</strong> (int):\nThe batch size.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>train_loader</strong> (torch.utils.data.DataLoader):\nThe training data loader.</li>\n<li><strong>test_loader</strong> (torch.utils.data.DataLoader):\nThe testing data loader.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">X_train</span>, </span><span class=\"param\"><span class=\"n\">Y_train</span>, </span><span class=\"param\"><span class=\"n\">X_test</span>, </span><span class=\"param\"><span class=\"n\">Y_test</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.rnn_model.loss_function", "modulename": "src.models.rnn_model", "qualname": "loss_function", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">Y_train</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.rnn_model.configure_model", "modulename": "src.models.rnn_model", "qualname": "configure_model", "kind": "function", "doc": "<p>Configures an RNN model for training.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_size</strong> (int):\nThe number of expected features in the input.</li>\n<li><strong>hidden_size</strong> (int):\nThe number of features in the hidden state.</li>\n<li><strong>output_size</strong> (int):\nThe number of output features.</li>\n<li><strong>learning_rate</strong> (float):\nThe learning rate.</li>\n<li><strong>device</strong> (str):\nThe device to use for training.</li>\n<li><strong>batch_first</strong> (bool, optional):\nIf True, then the input and output tensors are provided as (batch, seq, feature).\nDefault is True.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>model</strong> (torch.nn.Module):\nThe RNN model.</li>\n<li><strong>criterion</strong> (torch.nn.modules.loss._Loss):\nThe loss function.</li>\n<li><strong>optimizer</strong> (torch.optim.Optimizer):\nThe optimizer.</li>\n<li><strong>scheduler</strong> (torch.optim.lr_scheduler._LRScheduler):\nThe learning rate scheduler.</li>\n<li><strong>cross_entropy_weights</strong> (torch.Tensor):\nThe weights for the CrossEntropyLoss function.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">Y_train</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span>,</span><span class=\"param\">\t<span class=\"n\">learning_rate</span>,</span><span class=\"param\">\t<span class=\"n\">device</span>,</span><span class=\"param\">\t<span class=\"n\">batch_first</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.train_eval", "modulename": "src.models.train_eval", "kind": "module", "doc": "<p>This module contains functions for training and evaluating a Recurrent Neural Network (RNN) model.</p>\n\n<p>It includes functions for training the model for a specified number of epochs, training the model for one epoch, and evaluating the model on a test dataset. It also includes helper functions for debugging the model during training, such as checking for NaN and inf values in the input tensor, the gradients of the model, and the loss value, and computing the sum of squared gradients and parameters for the model.</p>\n\n<p>Functions:\n    train_eval_model(X_train, Y_train, X_test, Y_test, input_size, hidden_size, output_size, num_epochs, batch_size, learning_rate, device, batch_first=True, prints_per_epoch=10) -> (torch.nn.Module, numpy.ndarray): \n        Trains the RNN model and evaluates it on a test dataset.\n    train_loop(model, batch_size, device, prints_per_epoch, train_loader, criterion, optimizer, epoch) -> (float, float): \n        Trains an RNN model on a training dataset for one epoch.\n    test_loop(model, device, test_loader, criterion) -> (float, float, float, float, numpy.ndarray): \n        Evaluates the performance of a trained RNN model on a test dataset.</p>\n\n<p>Example:\n    To train and evaluate an RNN model with the provided functions, you would set up your data and hyperparameters, and then call:</p>\n\n<pre><code>&gt;&gt;&gt; model, labels_and_probs = train_eval_model(X_train, Y_train, X_test, Y_test, input_size=10, hidden_size=20, output_size=2, num_epochs=100, batch_size=32, learning_rate=0.001, device='cuda')\n</code></pre>\n\n<p>Note:\n    The training process is logged using TensorBoard, allowing for real-time monitoring of various metrics. It is assumed that the input data is preprocessed and formatted as NumPy arrays suitable for input to an RNN model.</p>\n"}, {"fullname": "src.models.train_eval.logger", "modulename": "src.models.train_eval", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.models.train_eval (WARNING)&gt;"}, {"fullname": "src.models.train_eval.train_eval_model", "modulename": "src.models.train_eval", "qualname": "train_eval_model", "kind": "function", "doc": "<p>Trains the RNN model and evaluates it on a test dataset.</p>\n\n<p>Args:\n    X_train (numpy.ndarray): The training input data.\n    Y_train (numpy.ndarray): The training target data.\n    X_test (numpy.ndarray): The testing input data.\n    Y_test (numpy.ndarray): The testing target data.\n    input_size (int): The number of expected features in the input.\n    hidden_size (int): The number of features in the hidden state.\n    output_size (int): The number of output features.\n    num_epochs (int): The number of epochs to train the model.\n    batch_size (int): The batch size.\n    learning_rate (float): The learning rate.\n    device (str): The device to use for training.\n    batch_first (bool, optional): If True, then the input and output tensors are provided as (batch, seq, feature). Default is True.\n    prints_per_epoch (int, optional): The number of times to print the loss per epoch. Default is 10.</p>\n\n<p>Returns:\n    model (torch.nn.Module): The trained RNN model.\n    labels_and_probs (numpy.ndarray): A numpy array containing the true labels, predicted labels, and predicted probabilities.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">X_train</span>,</span><span class=\"param\">\t<span class=\"n\">Y_train</span>,</span><span class=\"param\">\t<span class=\"n\">X_test</span>,</span><span class=\"param\">\t<span class=\"n\">Y_test</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span>,</span><span class=\"param\">\t<span class=\"n\">num_epochs</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span>,</span><span class=\"param\">\t<span class=\"n\">learning_rate</span>,</span><span class=\"param\">\t<span class=\"n\">device</span>,</span><span class=\"param\">\t<span class=\"n\">batch_first</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">prints_per_epoch</span><span class=\"o\">=</span><span class=\"mi\">10</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.train_eval.train_loop", "modulename": "src.models.train_eval", "qualname": "train_loop", "kind": "function", "doc": "<p>Trains an RNN model on a training dataset for one epoch.</p>\n\n<p>Args:\n    model (torch.nn.Module): The RNN model to train.\n    batch_size (int): The batch size.\n    device (str): The device to use for training.\n    prints_per_epoch (int): The number of times to print the loss per epoch.\n    train_loader (torch.utils.data.DataLoader): The training data loader.\n    criterion (torch.nn.modules.loss._Loss): The loss function.\n    optimizer (torch.optim.Optimizer): The optimizer.\n    epoch (int): The current epoch number.</p>\n\n<p>Returns:\n    train_loss (float): The average training loss over all batches.\n    train_f1 (float): The training F1 score.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span>,</span><span class=\"param\">\t<span class=\"n\">device</span>,</span><span class=\"param\">\t<span class=\"n\">prints_per_epoch</span>,</span><span class=\"param\">\t<span class=\"n\">train_loader</span>,</span><span class=\"param\">\t<span class=\"n\">criterion</span>,</span><span class=\"param\">\t<span class=\"n\">optimizer</span>,</span><span class=\"param\">\t<span class=\"n\">epoch</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.models.train_eval.test_loop", "modulename": "src.models.train_eval", "qualname": "test_loop", "kind": "function", "doc": "<p>Evaluates the performance of a trained RNN model on a test dataset.</p>\n\n<p>Args:\n    model (torch.nn.Module): The trained RNN model.\n    device (str): The device to use for evaluation.\n    test_loader (torch.utils.data.DataLoader): The test data loader.\n    criterion (torch.nn.modules.loss._Loss): The loss function.</p>\n\n<p>Returns:\n    test_loss (float): The average test loss over all batches.\n    test_acc (float): The test accuracy.\n    test_f1 (float): The test F1 score.\n    test_pr_auc (float): The test precision-recall AUC score.\n    labels_and_probs (numpy.ndarray): A numpy array containing the true labels, predicted labels, and predicted probabilities.</p>\n\n<p>TODO: Check/integrate changes from FD.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">device</span>, </span><span class=\"param\"><span class=\"n\">test_loader</span>, </span><span class=\"param\"><span class=\"n\">criterion</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils", "modulename": "src.utils", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.utils.utilities", "modulename": "src.utils.utilities", "kind": "module", "doc": "<p>This module contains utility functions for data preprocessing and feature engineering.</p>\n\n<p>It includes functions for hashing objects, creating configuration dictionaries, and engineering features for a DataFrame. The feature engineering function uses the <code>FeatureEngineer</code> class from the <code>src.data_preprocess.feature_engineering</code> module.</p>\n\n<p>Functions:\n    get_hash(obj) -> str: \n        Returns the hash value of an object as a string.\n    create_config_dict(model_name, input_size, hidden_size, output_size, num_epochs, batch_size, learning_rate, raw_data_path, interim_data_path, processed_data_path, logging_level, logging_format) -> dict: \n        Creates a configuration dictionary with the provided parameters.</p>\n\n<p>Example:\n    To use the feature engineering function, you can pass a pandas DataFrame:</p>\n\n<pre><code>&gt;&gt;&gt; df = pd.DataFrame(data)\n&gt;&gt;&gt; engineered_df = engineer_features(df)\n</code></pre>\n\n<p>Note:\n    The module expects a specific structure for the input dataframe as required by the FeatureEngineer class for the standardization of features.</p>\n"}, {"fullname": "src.utils.utilities.logger", "modulename": "src.utils.utilities", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.utils.utilities (WARNING)&gt;"}, {"fullname": "src.utils.utilities.get_hash", "modulename": "src.utils.utilities", "qualname": "get_hash", "kind": "function", "doc": "<p>Returns the hash value of an object as a string.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>obj</strong> (object):\nThe object to hash.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>str</strong>: The hash value of the object as a string.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">obj</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utils.utilities.create_config_dict", "modulename": "src.utils.utilities", "qualname": "create_config_dict", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_name</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span>,</span><span class=\"param\">\t<span class=\"n\">num_epochs</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span>,</span><span class=\"param\">\t<span class=\"n\">learning_rate</span>,</span><span class=\"param\">\t<span class=\"n\">raw_data_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">interim_data_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">processed_data_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">logging_level</span><span class=\"o\">=</span><span class=\"s1\">&#39;INFO&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">logging_format</span><span class=\"o\">=</span><span class=\"s1\">&#39;</span><span class=\"si\">%(asctime)s</span><span class=\"s1\"> - </span><span class=\"si\">%(levelname)s</span><span class=\"s1\"> - </span><span class=\"si\">%(message)s</span><span class=\"s1\">&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();